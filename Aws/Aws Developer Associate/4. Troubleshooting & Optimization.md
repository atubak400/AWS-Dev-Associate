

### 1. Using EventBridge for Event-Driven Automation

- If you need to trigger a Lambda function based on specific CodeCommit events, such as pullRequestCreated or pullRequestSourceBranchUpdated, use EventBridge. It provides a direct and efficient mechanism for detecting events and triggering the appropriate Lambda function, reducing complexity and ensuring timely execution.

### 2. Using CloudWatch Custom Metrics for Error Monitoring

- If you need to monitor the error rate of external API calls and alert the support team when it exceeds a threshold, use custom metrics in Amazon CloudWatch. Track failures, configure alarms, and notify the team via Amazon SNS when conditions are met.

### 3. Using Pre-Baked AMIs for Faster EC2 Scaling

- To improve the provisioning time of EC2 instances in an Auto Scaling group, use EC2 Image Builder to create pre-baked AMIs that include the latest application code, dependencies, and patches. This approach ensures faster scaling and minimizes downtime during peak loads. Avoid relying solely on UserData scripts or manual deployment methods, as they increase provisioning time and complexity.

- EC2 UserData scripts are scripts or commands that are provided to an Amazon EC2 instance at the time of launch. These scripts are executed by the instance during its first boot to automate tasks such as installing software, configuring the instance, or starting specific applications.

### 4. Scaling and Optimizing Kinesis for Increased Traffic

- If your Kinesis stream encounters throughput exceptions, reshard your stream to scale capacity and reduce the frequency or size of your requests to optimize producer behavior. These strategies address write-side limitations effectively and help your stream handle increased traffic efficiently. 

- Resharding your stream to scale capacity means increasing the number of shards in your Kinesis stream to handle higher data throughput by distributing the load across more shards

- Reducing the frequency or size of your requests optimizes producer behavior by sending smaller or fewer data chunks, minimizing the risk of exceeding the stream's write limits.

### 5. Efficient Log Analysis with CloudWatch Logs Insights

- For analyzing recent log data in CloudWatch Logs and identifying the most expensive Lambda requests, use CloudWatch Logs Insights. It provides a simple, interactive querying experience directly in the CloudWatch console

- CloudWatch Logs Insights enables you to interactively search and analyze your log data in Amazon CloudWatch Logs. It automatically discovers fields in logs from AWS services, such as Route 53, Lambda, CloudTrail, VPC Flow Logs, and any application or custom log that emits log events as JSON.

### 6. Optimizing DynamoDB Scans During Heavy Loads

- Run parallel scans to process table segments concurrently, significantly reducing the total scan time.
- Reduce the page size to improve request processing times and manage read capacity unit usage more effectively. These methods directly align with AWS's best practices for handling high scan loads.
- DynamoDB uses eventually consistent reads by default. Eventually consistent reads allow you to read data quickly, but it may not reflect the most recent updates immediately, syncing to the latest version over time.

### 7. Automating Notifications for Build Failures in Continuous Integration

- To set up continuous integration with CodeBuild and ensure the DevOps team is notified of build failures:
    - Store the source code in CodeCommit to integrate the latest code seamlessly into the build process. CodeCommit is a supported source code repository for CodeBuild.
    - Use Amazon EventBridge to capture build events and integrate it with Amazon SNS to send SMS notifications to the team. This ensures timely alerts and efficient monitoring of build processes.

### 8. Troubleshooting API Gateway Timeouts
- IntegrationLatency metric measures the time taken by API Gateway to send the request to the backend Lambda function(for example) and receive a response.
- Latency metric measures the total time taken by API Gateway to process a request, including both the request processing time and the backend integration time. A high latency value indicates that the overall API request-response cycle is taking too long, potentially causing the timeouts.
- When troubleshooting API Gateway timeouts, check the IntegrationLatency metric to identify delays in communicating with the backend Lambda function and the Latency metric to evaluate the overall request processing time.

### 9. DAX for High Read Traffic Optimization

- When experiencing high read traffic in DynamoDB, configuring a DAX cluster is the most effective and immediate solution. It enhances performance by reducing latency through caching, ensuring smooth operation during high-demand periods without requiring structural changes to the table.

### 10. ProvisionedThroughputExceededException error
- The ProvisionedThroughputExceededException error in DynamoDB occurs when the number of requests to a table or a global secondary index exceeds the provisioned read or write capacity. This error is a signal that the demand for the table is higher than the capacity allocated for it.

### 11. Handling UnprocessedKeys in DynamoDB BatchGetItem Responses

- To handle unprocessed keys in BatchGetItem responses, leverage the AWS SDK for JavaScript (or other SDKs) to automatically implement retries with exponential backoff. This ensures efficient error handling and maximizes the success rate of batch operations without additional manual intervention. If using custom logic, always implement retries with exponential backoff to handle transient errors effectively.

### 12. Exponential Backoffs

- Exponential backoff is a way to manage retries when something temporarily fails, like a network issue or an overloaded server. Instead of retrying immediately or at fixed intervals, you wait a little longer each time before trying again.

- For example, after the first failure, you might wait 1 second, then 2 seconds after the next failure, then 4 seconds, and so on. This gives the system or service you’re trying to reach some time to recover while avoiding adding more strain by retrying too often. 

- It’s like giving someone extra time to catch their breath after each failed attempt to answer a question. This approach helps reduce congestion and increases the chances that your retries will succeed.

### 13. AWS SDK Exponential Backoffs

- In the context of AWS SDKs for reliable batch operations, exponential backoff is a strategy used to handle situations where some requests fail temporarily, such as when the system is throttled or experiences transient errors. For example, when you use BatchGetItem in DynamoDB, the response may include unprocessed keys if the service couldn’t handle some of the requests due to throughput limits or other temporary conditions.

- AWS SDKs automatically retry these unprocessed requests, applying exponential backoff to manage the retries. This means that after each failed attempt, the SDK waits progressively longer—starting with a short delay and doubling it with each subsequent retry. This approach gives DynamoDB time to recover, avoids overloading the service, and ensures that the unprocessed keys are eventually retrieved without manual intervention.

### 14. Using AWS SDKs for Reliable Batch Operations

- To handle unprocessed keys in BatchGetItem responses, leverage the AWS SDK for JavaScript (or other SDKs) to automatically implement retries with exponential backoff. This ensures efficient error handling and maximizes the success rate of batch operations without additional manual intervention.

- If using custom logic, always implement retries with exponential backoff to handle transient errors effectively.

### 15. AWS Serverless Application Repository (SAR)

- The AWS Serverless Application Repository (SAR) is a service where you can find and share ready-made serverless applications. These are pre-built solutions designed to run on AWS services like Lambda, so you don’t have to build everything from scratch. 

- You can browse a collection of apps for tasks like data processing, monitoring, or machine learning, then quickly deploy them to your AWS account. 

### 16. Leveraging Pre-Built Serverless Applications with SAR

- For a company built on AWS serverless architecture looking to accelerate development with pre-built solutions, the AWS Serverless Application Repository (SAR) is the best service. It provides a library of serverless applications, enabling rapid deployment and customization to meet new business requirements.

### 17. ALB access logs

- ALB access logs are detailed records of all the requests handled by your Application Load Balancer (ALB) in AWS. These logs include useful information like the time of the request, the IP address of the client, the requested URL, the response code, and more. They are stored in an Amazon S3 bucket and can help you troubleshoot issues, monitor traffic, and analyze usage patterns.

### 18. Analyzing Request Patterns with ALB Access Logs

- The feature on the Load Balancer that helps analyze incoming requests for latencies and client IP address patterns is the ALB access logs. These logs provide the granular details needed to understand traffic patterns and optimize application performance.

### 19. Handling Periodic Spikes in Kinesis Streams

- When encountering periodic spikes that lead to ProvisionedThroughputExceededException:

    - Implement exponential backoff for retries to handle temporary capacity issues gracefully.
    - Decrease the frequency or size of your requests to avoid overwhelming the shards.

### 20. X-Ray sampling

- X-Ray sampling is a mechanism used to control the amount of data that X-Ray collects to reduce overhead, particularly in high-traffic applications. While it helps manage the volume of tracing data, it does not help with debugging issues related to why the application fails to send data to X-Ray.

### 21. Understanding Debugging Tools for X-Ray Issues

- When an application fails to send data to X-Ray, ensure:

    - The EC2 instance role is correctly configured with the necessary permissions.
    - The EC2 X-Ray Daemon is running and properly configured.
    - Use CloudTrail to monitor API activity for any potential errors.
    - X-Ray sampling does not provide insights for debugging connectivity or configuration issues.

### 22. Auditing SSM Parameter Store Access

- To generate a report for auditing SSM Parameter Store activity:

    - Use AWS CloudTrail, which tracks all API calls to SSM Parameter Store.
    - Configure CloudTrail to store logs in S3 or send them to CloudWatch Logs for further analysis if required.

### 23. Using X-Ray for Cross-Account Distributed Tracing

- AWS X-Ray helps you track and debug issues in applications that span multiple AWS accounts. It collects detailed trace data from different parts of your application, even if they are running in separate accounts. 

- This makes it easier to see how requests flow through your entire system, find bottlenecks, and fix errors. With its centralized view, X-Ray gives teams a clear picture of performance across all accounts, making debugging and monitoring distributed applications much simpler.

- For debugging and tracing across multiple AWS accounts, use AWS X-Ray. It provides detailed trace information and centralized visualization, helping teams identify performance issues and errors in distributed applications.

### 24. Optimize API Performance with Caching
- If your API serves frequently requested, daily updated data, enabling API caching in API Gateway is the most straightforward and effective way to improve performance by reducing latency and backend load.

### 25. API Gateway Mapping Templates

- API Gateway Mapping Templates are tools that let you change the way data is sent to or received from your APIs without changing the backend. 
- They use a scripting language called Velocity Template Language (VTL) to transform requests or responses. For example, you can reformat data, hide certain fields, or convert it into a different structure before sending it to the client or backend. 
- This helps you customize how your API works without modifying your backend logic, making it easier to adapt to different use cases.

### 26. Ensuring Proper Configuration of Health Checks in ALB

- If EC2 instances are marked as unhealthy by an ALB, check:

    - Security Group Rules: Ensure the ALB’s security group can communicate with the EC2 instances on the health check port.
    - Health Check Route: Verify the health check path is correctly configured and returns a 2xx status code. A 2xx response is an HTTP status code category that indicates a successful request. It means the client's request was received, understood, and processed correctly by the server. e.g. 200, 201, 202, 204.

### 27. Optimizing AWS Lambda for CPU-Intensive Workloads

- To make AWS Lambda faster for CPU-heavy tasks, you can increase its memory allocation. When you do this, AWS automatically gives the function more CPU power as well, helping it process tasks quicker. Don’t waste time adjusting unrelated settings, like the AWS Region or Lambda layers, because these won’t directly improve how fast the function runs. Focusing on memory is the most effective way to boost performance for CPU-intensive workloads.


### 28. Backlog per instance metric and Target tracking scaling policy

- The backlog per instance metric shows how many tasks or messages are waiting to be processed by each running ECS instance. It helps measure workload pressure. - When combined with a target tracking scaling policy, you can automatically adjust the number of ECS tasks to keep the backlog at a manageable level. For example, if the backlog grows because of high traffic, more tasks are launched to process it faster, and when traffic slows down, the tasks scale back down. This approach keeps your application responsive while controlling costs.

### 29. Optimizing ECS with SQS for Variable Workloads

- To handle variable traffic spikes and improve order processing performance:

    - Use the backlog per instance metric to monitor the workload.
    - Combine it with a target tracking scaling policy to dynamically scale ECS tasks based on SQS queue depth.

### 30. Understanding EC2 User Data Behavior

- By default, user data scripts run with root privileges, enabling administrative setup tasks during instance initialization.
- These scripts execute only during the first boot cycle.